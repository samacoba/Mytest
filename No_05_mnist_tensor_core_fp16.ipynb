{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tensor Coreの効果を調査\n",
    "* FP16 拡大6層 MNIST ,単層全結合\n",
    "* 自宅PC RTX2080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform: Windows-10-10.0.17763-SP0\n",
      "Chainer: 7.0.0a1\n",
      "NumPy: 1.16.2\n",
      "CuPy:\n",
      "  CuPy Version          : 7.0.0a1\n",
      "  CUDA Root             : C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\n",
      "  CUDA Build Version    : 10010\n",
      "  CUDA Driver Version   : 10010\n",
      "  CUDA Runtime Version  : 10010\n",
      "  cuDNN Build Version   : 7500\n",
      "  cuDNN Version         : 7500\n",
      "  NCCL Build Version    : None\n",
      "  NCCL Runtime Version  : None\n",
      "iDeep: Not Available\n"
     ]
    }
   ],
   "source": [
    "# FP16 拡大6層 MNIST\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import training\n",
    "from chainer.training import extensions\n",
    "import numpy as np\n",
    "\n",
    "chainer.global_config.dtype =  np.float16\n",
    "#chainer.global_config.dtype =  np.float32\n",
    "device = chainer.get_device('0')\n",
    "unit =4096\n",
    "batchsize = 4096\n",
    "epoch = 20\n",
    "\n",
    "chainer.print_runtime_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network definition\n",
    "class MLP(chainer.Chain):\n",
    "\n",
    "    def __init__(self, n_units, n_out):\n",
    "        super(MLP, self).__init__()\n",
    "        with self.init_scope():\n",
    "            # the size of the inputs to each layer will be inferred\n",
    "            self.l1 = L.Linear(None, n_units)  # n_in -> n_units\n",
    "            self.l2 = L.Linear(None, n_units)  # n_units -> n_units\n",
    "            self.l3 = L.Linear(None, n_units)  # n_units -> n_units\n",
    "            self.l4 = L.Linear(None, n_units)  # n_units -> n_units\n",
    "            self.l5 = L.Linear(None, n_units)  # n_units -> n_units\n",
    "            self.l6 = L.Linear(None, n_out)  # n_units -> n_out\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        h3 = F.relu(self.l3(h2))\n",
    "        h4 = F.relu(self.l4(h3))\n",
    "        h5 = F.relu(self.l5(h4))\n",
    "        return self.l6(h5)\n",
    "\n",
    "# Set up a neural network to train\n",
    "model = L.Classifier(MLP(unit, 10))\n",
    "model.to_device(device)\n",
    "device.use()\n",
    "\n",
    "# Setup an optimizer\n",
    "#optimizer = chainer.optimizers.Adam()\n",
    "optimizer = chainer.optimizers.SGD()\n",
    "optimizer.setup(model)\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train, test = chainer.datasets.get_mnist()\n",
    "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
    "test_iter = chainer.iterators.SerialIterator(test, batchsize,repeat=False, shuffle=False)\n",
    "\n",
    "# Set up a trainer\n",
    "updater = training.updaters.StandardUpdater( train_iter, optimizer, device=device)\n",
    "trainer = training.Trainer(updater, (epoch, 'epoch'), out='result')\n",
    "trainer.extend(extensions.Evaluator(test_iter, model, device=device))\n",
    "trainer.extend(extensions.LogReport())\n",
    "trainer.extend(extensions.PrintReport(\n",
    "    ['epoch', 'main/loss', 'validation/main/loss',\n",
    "     'main/accuracy', 'validation/main/accuracy', 'elapsed_time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
      "1           2.29492     2.2832                0.149536       0.232422                  3.08555       \n",
      "2           2.27344     2.25977               0.265137       0.291504                  3.887         \n",
      "3           2.25195     2.24023               0.315186       0.339844                  4.63864       \n",
      "4           2.23047     2.21484               0.371826       0.4104                    5.44276       \n",
      "5           2.20898     2.18945               0.44458        0.477539                  6.24275       \n",
      "6           2.18359     2.16602               0.500977       0.527344                  7.008         \n",
      "7           2.1582      2.13477               0.55127        0.574707                  7.80822       \n",
      "8           2.12891     2.10352               0.587891       0.61084                   8.63134       \n",
      "9           2.09766     2.06836               0.619629       0.638672                  9.38277       \n",
      "10          2.05859     2.02539               0.64502        0.663574                  10.1982       \n",
      "11          2.01953     1.97656               0.67041        0.688965                  10.9999       \n",
      "12          1.96777     1.9248                0.687012       0.705566                  11.7719       \n",
      "13          1.91309     1.85938               0.700684       0.717285                  12.5925       \n",
      "14          1.8457      1.78516               0.710938       0.73291                   13.3944       \n",
      "15          1.77246     1.70605               0.722168       0.742188                  14.165        \n",
      "16          1.68848     1.61328               0.728516       0.751953                  14.9963       \n",
      "17          1.59473     1.5127                0.736816       0.76709                   15.8034       \n",
      "18          1.50195     1.41699               0.750977       0.777832                  16.5641       \n",
      "19          1.40527     1.31348               0.76123        0.787598                  17.3671       \n",
      "20          1.31055     1.22363               0.773926       0.79834                   18.132        \n"
     ]
    }
   ],
   "source": [
    "# Run the training mnist\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable(1031.)\n",
      "計算時間：3.340 s\n",
      "計算速度：41.147 TFlops\n"
     ]
    }
   ],
   "source": [
    "# FP16 単層全結合\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import time\n",
    "\n",
    "COUNT = 1000\n",
    "N = 4096   \n",
    "x = np.random.uniform(size=(N, N))\n",
    "W = np.random.uniform(size=(N, N))\n",
    "\n",
    "x = chainer.Variable(cp.asarray(x,dtype= np.float16))\n",
    "W = chainer.Variable(cp.asarray(W,dtype= np.float16))\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(COUNT):\n",
    "    y = F.linear(x, W, b=None, n_batch_axes=1)  \n",
    "    \n",
    "print(y[0][0])\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "\n",
    "print('計算時間：{:.3f} s'.format(elapsed))\n",
    "print('計算速度：{:.3f} TFlops'.format(1e-12* COUNT * 2*N*N*N / elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
